{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9996b1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: h5py in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (1.6.2)\n",
      "Requirement already satisfied: pyyaml in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (1.19.2)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from h5py->keras) (1.15.0)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a5a106b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "  \n",
    "img_width, img_height = 224, 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e08e9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = 'split_images/train'\n",
    "validation_data_dir = 'split_images/valid'\n",
    "nb_train_samples =1044\n",
    "nb_validation_samples = 294\n",
    "epochs = 40\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9737b733",
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f13e5464",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (2, 2), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "  \n",
    "model.add(Conv2D(32, (2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "  \n",
    "model.add(Conv2D(64, (2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "  \n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a70d9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "419f6b8d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1044 images belonging to 2 classes.\n",
      "Found 294 images belonging to 2 classes.\n",
      "Epoch 1/40\n",
      "11/65 [====>.........................] - ETA: 57s - loss: 2.2322 - accuracy: 0.4354 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\Image.py:962: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 85s 1s/step - loss: 1.1942 - accuracy: 0.5054 - val_loss: 0.6665 - val_accuracy: 0.5938\n",
      "Epoch 2/40\n",
      "65/65 [==============================] - 86s 1s/step - loss: 0.6924 - accuracy: 0.5498 - val_loss: 0.6285 - val_accuracy: 0.6562\n",
      "Epoch 3/40\n",
      "65/65 [==============================] - 84s 1s/step - loss: 0.6593 - accuracy: 0.6496 - val_loss: 0.6275 - val_accuracy: 0.6250\n",
      "Epoch 4/40\n",
      "65/65 [==============================] - 83s 1s/step - loss: 0.6246 - accuracy: 0.6703 - val_loss: 0.5611 - val_accuracy: 0.7049\n",
      "Epoch 5/40\n",
      "65/65 [==============================] - 85s 1s/step - loss: 0.6029 - accuracy: 0.6850 - val_loss: 0.5677 - val_accuracy: 0.7257\n",
      "Epoch 6/40\n",
      "65/65 [==============================] - 83s 1s/step - loss: 0.5778 - accuracy: 0.7083 - val_loss: 0.8651 - val_accuracy: 0.6042\n",
      "Epoch 7/40\n",
      "65/65 [==============================] - 83s 1s/step - loss: 0.5760 - accuracy: 0.7060 - val_loss: 0.6284 - val_accuracy: 0.6771\n",
      "Epoch 8/40\n",
      "65/65 [==============================] - 82s 1s/step - loss: 0.5155 - accuracy: 0.7439 - val_loss: 0.5306 - val_accuracy: 0.7431\n",
      "Epoch 9/40\n",
      "65/65 [==============================] - 82s 1s/step - loss: 0.5455 - accuracy: 0.7287 - val_loss: 0.5683 - val_accuracy: 0.7049\n",
      "Epoch 10/40\n",
      "65/65 [==============================] - 83s 1s/step - loss: 0.5009 - accuracy: 0.7568 - val_loss: 0.5020 - val_accuracy: 0.7743\n",
      "Epoch 11/40\n",
      "65/65 [==============================] - 82s 1s/step - loss: 0.5383 - accuracy: 0.7612 - val_loss: 0.5244 - val_accuracy: 0.7465\n",
      "Epoch 12/40\n",
      "65/65 [==============================] - 83s 1s/step - loss: 0.4793 - accuracy: 0.7831 - val_loss: 0.5977 - val_accuracy: 0.7118\n",
      "Epoch 13/40\n",
      "65/65 [==============================] - 82s 1s/step - loss: 0.5203 - accuracy: 0.7526 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
      "Epoch 14/40\n",
      "65/65 [==============================] - 82s 1s/step - loss: 0.4910 - accuracy: 0.7877 - val_loss: 0.5096 - val_accuracy: 0.7500\n",
      "Epoch 15/40\n",
      "65/65 [==============================] - 82s 1s/step - loss: 0.4774 - accuracy: 0.7725 - val_loss: 0.4949 - val_accuracy: 0.7604\n",
      "Epoch 16/40\n",
      "65/65 [==============================] - 82s 1s/step - loss: 0.4606 - accuracy: 0.7906 - val_loss: 0.4923 - val_accuracy: 0.7639\n",
      "Epoch 17/40\n",
      "65/65 [==============================] - 83s 1s/step - loss: 0.4614 - accuracy: 0.7944 - val_loss: 0.4857 - val_accuracy: 0.7639\n",
      "Epoch 18/40\n",
      "65/65 [==============================] - 83s 1s/step - loss: 0.4431 - accuracy: 0.8090 - val_loss: 0.4577 - val_accuracy: 0.7917\n",
      "Epoch 19/40\n",
      "65/65 [==============================] - 84s 1s/step - loss: 0.4488 - accuracy: 0.8006 - val_loss: 0.5863 - val_accuracy: 0.7569\n",
      "Epoch 20/40\n",
      "65/65 [==============================] - 83s 1s/step - loss: 0.5042 - accuracy: 0.7869 - val_loss: 0.4635 - val_accuracy: 0.7882\n",
      "Epoch 21/40\n",
      "65/65 [==============================] - 82s 1s/step - loss: 0.4384 - accuracy: 0.8077 - val_loss: 0.4526 - val_accuracy: 0.7986\n",
      "Epoch 22/40\n",
      "65/65 [==============================] - 82s 1s/step - loss: 0.4165 - accuracy: 0.8238 - val_loss: 0.4450 - val_accuracy: 0.7917\n",
      "Epoch 23/40\n",
      "65/65 [==============================] - 84s 1s/step - loss: 0.4155 - accuracy: 0.8172 - val_loss: 0.4997 - val_accuracy: 0.7917\n",
      "Epoch 24/40\n",
      "65/65 [==============================] - 73s 1s/step - loss: 0.4006 - accuracy: 0.8209 - val_loss: 0.8265 - val_accuracy: 0.7431\n",
      "Epoch 25/40\n",
      "65/65 [==============================] - 68s 1s/step - loss: 0.4290 - accuracy: 0.8030 - val_loss: 0.4156 - val_accuracy: 0.7951\n",
      "Epoch 26/40\n",
      "65/65 [==============================] - 66s 1s/step - loss: 0.3741 - accuracy: 0.8476 - val_loss: 0.4923 - val_accuracy: 0.7500\n",
      "Epoch 27/40\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.3442 - accuracy: 0.8388 - val_loss: 0.5320 - val_accuracy: 0.7882\n",
      "Epoch 28/40\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.3525 - accuracy: 0.8393 - val_loss: 0.4051 - val_accuracy: 0.8194\n",
      "Epoch 29/40\n",
      "65/65 [==============================] - 65s 989ms/step - loss: 0.4464 - accuracy: 0.8224 - val_loss: 0.4048 - val_accuracy: 0.8160\n",
      "Epoch 30/40\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.3535 - accuracy: 0.8497 - val_loss: 0.3928 - val_accuracy: 0.8229\n",
      "Epoch 31/40\n",
      "65/65 [==============================] - 66s 1s/step - loss: 0.3697 - accuracy: 0.8295 - val_loss: 0.4593 - val_accuracy: 0.8229\n",
      "Epoch 32/40\n",
      "65/65 [==============================] - 65s 1s/step - loss: 0.3588 - accuracy: 0.8507 - val_loss: 0.4420 - val_accuracy: 0.8299\n",
      "Epoch 33/40\n",
      "65/65 [==============================] - 66s 1s/step - loss: 0.3986 - accuracy: 0.8206 - val_loss: 0.5717 - val_accuracy: 0.7882\n",
      "Epoch 34/40\n",
      "65/65 [==============================] - 65s 990ms/step - loss: 0.4032 - accuracy: 0.8293 - val_loss: 0.3873 - val_accuracy: 0.8333\n",
      "Epoch 35/40\n",
      "65/65 [==============================] - 64s 989ms/step - loss: 0.3308 - accuracy: 0.8553 - val_loss: 0.3824 - val_accuracy: 0.8681\n",
      "Epoch 36/40\n",
      "65/65 [==============================] - 64s 970ms/step - loss: 0.3585 - accuracy: 0.8548 - val_loss: 0.5058 - val_accuracy: 0.7639\n",
      "Epoch 37/40\n",
      "65/65 [==============================] - 64s 983ms/step - loss: 0.3307 - accuracy: 0.8632 - val_loss: 0.3803 - val_accuracy: 0.8611\n",
      "Epoch 38/40\n",
      "65/65 [==============================] - 63s 958ms/step - loss: 0.3126 - accuracy: 0.8768 - val_loss: 0.4739 - val_accuracy: 0.8194\n",
      "Epoch 39/40\n",
      "65/65 [==============================] - 63s 964ms/step - loss: 0.3406 - accuracy: 0.8448 - val_loss: 0.5428 - val_accuracy: 0.8403\n",
      "Epoch 40/40\n",
      "65/65 [==============================] - 62s 955ms/step - loss: 0.3485 - accuracy: 0.8473 - val_loss: 0.4339 - val_accuracy: 0.8299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20b8d1a80d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "\trescale=1. / 255,\n",
    "\tshear_range=0.2,\n",
    "\tzoom_range=0.2,\n",
    "\thorizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "\ttrain_data_dir,\n",
    "\ttarget_size=(img_width, img_height),\n",
    "\tbatch_size=batch_size,\n",
    "\tclass_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "\tvalidation_data_dir,\n",
    "\ttarget_size=(img_width, img_height),\n",
    "\tbatch_size=batch_size,\n",
    "\tclass_mode='binary')\n",
    "\n",
    "model.fit(\n",
    "\ttrain_generator,\n",
    "\tsteps_per_epoch=nb_train_samples // batch_size,\n",
    "\tepochs=epochs,\n",
    "\tvalidation_data=validation_generator,\n",
    "\tvalidation_steps=nb_validation_samples // batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25b82576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 46s 698ms/step - loss: 0.2888 - accuracy: 0.8956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2887944281101227, 0.8955938816070557]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "862d8880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 9s 474ms/step - loss: 0.4379 - accuracy: 0.8299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4379478991031647, 0.8299319744110107]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906e9adc",
   "metadata": {},
   "source": [
    "e=10, b=32 :70 high rise\n",
    "e:15, b=32 :81.13,75.5\n",
    "      b=64 :66.9,61.56\n",
    "      b=16 :81.8, 73.47\n",
    "e:20, b=16 :83.05, 81.97\n",
    "e:25, b:16 :85.44, 81.63 (37)\n",
    "e:25, b:32 :81.90, 81.97\n",
    "e:40, b:16 :89.56, 82.99\n",
    "model.save_weights('model_saved.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6058f2ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
